@InProceedings{10.1007/978-3-030-64919-7_8,
author="van der Himst, Otto
and Lanillos, Pablo",
editor="Verbelen, Tim
and Lanillos, Pablo
and Buckley, Christopher L.
and De Boom, Cedric",
title="Deep Active Inference for Partially Observable MDPs",
booktitle="Active Inference",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="61--71",
abstract="Deep active inference has been proposed as a scalable approach to perception and action that deals with large policy and state spaces. However, current models are limited to fully observable domains. In this paper, we describe a deep active inference model that can learn successful policies directly from high-dimensional sensory inputs. The deep learning architecture optimizes a variant of the expected free energy and encodes the continuous state representation by means of a variational autoencoder. We show, in the OpenAI benchmark, that our approach has comparable or better performance than deep Q-learning, a state-of-the-art deep reinforcement learning algorithm.",
isbn="978-3-030-64919-7"
}

