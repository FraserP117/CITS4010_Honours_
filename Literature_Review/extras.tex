
The principle aims are 
RxInfer.jl, see the mountaincar implementation: https://biaslab.github.io/RxInfer.jl
OpenAI gym and Atari Environments
DeepMind Control Suite \textcite{Deep-Mind-Control-Suite}
the distracting control suite 
minigrid env \textcite{minigrid}



\section{Research Objectives}
Reinforcement Learning has enjoyed a great deal of success in the attempt to scale to higher dimensional, continuous, noisy environments. While there is still much to be done on this front, Active Inference has thus far been almost entirely limited to small, discrete, stationary environments. Given that Active Inference represents a potentially unifying paradigm - owing to its generality - and that it has no dependence on any ad-hoc scalar reward signal, it is plausible to suppose that Active Inference might enjoy several theoretical advantages over more ``traditional'' methods in Reinforcement Learning and Optimal Control. 

Hence, in the course of this proposed thesis, we shall implement various Active Inference and RL agents, in both the the fully observable and partially observable cases, with and without various sources of uncertainty and in both benchmark ``low-dimensional'' environments and non-trivial ``higher-dimensional'' environments. The aim will be to asses the relative advantages and disadvantages of both ``approach families'' as these pertain to their ability to effectively deal with the various kinds of uncertainty mentioned above, in addition to their ability to scale up into higher-dimensional environments.     
