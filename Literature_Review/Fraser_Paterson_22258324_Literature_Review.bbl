% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{Reactive-MP}{article}{}
      \name{author}{2}{}{%
        {{hash=63366e44ffa7043ff4bd1398c7a44165}{%
           family={Bagaev},
           familyi={B\bibinitperiod},
           given={Dmitry},
           giveni={D\bibinitperiod}}}%
        {{hash=2caeea1b18c3a6d6099b66a5232eb983}{%
           family={Vries},
           familyi={V\bibinitperiod},
           given={Bert},
           giveni={B\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \strng{namehash}{bec4896e4bdcafc0e730fadcbf0f4602}
      \strng{fullhash}{bec4896e4bdcafc0e730fadcbf0f4602}
      \strng{bibnamehash}{bec4896e4bdcafc0e730fadcbf0f4602}
      \strng{authorbibnamehash}{bec4896e4bdcafc0e730fadcbf0f4602}
      \strng{authornamehash}{bec4896e4bdcafc0e730fadcbf0f4602}
      \strng{authorfullhash}{bec4896e4bdcafc0e730fadcbf0f4602}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{CoRR}
      \field{title}{Reactive Message Passing for Scalable Bayesian Inference}
      \field{volume}{abs/2112.13251}
      \field{year}{2021}
      \verb{eprint}
      \verb 2112.13251
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2112.13251
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2112.13251
      \endverb
    \endentry
    \entry{Bayes-State-Estimation}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0fd156a15a478f90a7dc3353dc1a3e97}{%
           family={Balaji},
           familyi={B\bibinitperiod},
           given={Bhashyam},
           giveni={B\bibinitperiod}}}%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
      }
      \name{editor}{1}{}{%
        {{hash=7b704fc0a28053bb266d11dd0b255e67}{%
           family={Kadar},
           familyi={K\bibinitperiod},
           given={Ivan},
           giveni={I\bibinitperiod}}}%
      }
      \list{organization}{2}{%
        {International Society for Optics}%
        {Photonics}%
      }
      \list{publisher}{1}{%
        {SPIE}%
      }
      \strng{namehash}{48e06832f1075687069b9d3116242b3a}
      \strng{fullhash}{48e06832f1075687069b9d3116242b3a}
      \strng{bibnamehash}{48e06832f1075687069b9d3116242b3a}
      \strng{authorbibnamehash}{48e06832f1075687069b9d3116242b3a}
      \strng{authornamehash}{48e06832f1075687069b9d3116242b3a}
      \strng{authorfullhash}{48e06832f1075687069b9d3116242b3a}
      \strng{editorbibnamehash}{7b704fc0a28053bb266d11dd0b255e67}
      \strng{editornamehash}{7b704fc0a28053bb266d11dd0b255e67}
      \strng{editorfullhash}{7b704fc0a28053bb266d11dd0b255e67}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Signal Processing, Sensor Fusion, and Target Recognition XX}
      \field{title}{{Bayesian state estimation using generalized coordinates}}
      \field{volume}{8050}
      \field{year}{2011}
      \field{pages}{80501Y}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1117/12.883513
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1117/12.883513
      \endverb
      \verb{url}
      \verb https://doi.org/10.1117/12.883513
      \endverb
      \keyw{Variational Bayes,Variational Filtering,Generalized Coordinates,Dynamical Causal Modelling,Hierarchical Dynamical Model,Continuous-Discrete Filtering,Kolmogorov Equation,Fokker-Planck Equation}
    \endentry
    \entry{Variational-Inference-Reviews}{article}{}
      \name{author}{3}{}{%
        {{hash=108998f0d44d4dce8ccb93e4d78cd5c6}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=9b4bd774638a5e11db087a94dc4950b1}{%
           family={Kucukelbir},
           familyi={K\bibinitperiod},
           given={Alp},
           giveni={A\bibinitperiod}}}%
        {{hash=2baf42315daa7e7288615fe2776de8e6}{%
           family={McAuliffe},
           familyi={M\bibinitperiod},
           given={Jon\bibnamedelima D.},
           giveni={J\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Informa {UK} Limited}%
      }
      \strng{namehash}{853d35e6ec8363e2400561dba8cb9aae}
      \strng{fullhash}{853d35e6ec8363e2400561dba8cb9aae}
      \strng{bibnamehash}{853d35e6ec8363e2400561dba8cb9aae}
      \strng{authorbibnamehash}{853d35e6ec8363e2400561dba8cb9aae}
      \strng{authornamehash}{853d35e6ec8363e2400561dba8cb9aae}
      \strng{authorfullhash}{853d35e6ec8363e2400561dba8cb9aae}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of the American Statistical Association}
      \field{month}{04}
      \field{number}{518}
      \field{title}{Variational Inference: A Review for Statisticians}
      \field{volume}{112}
      \field{year}{2017}
      \field{pages}{859\bibrangedash 877}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1080/01621459.2017.1285773
      \endverb
    \endentry
    \entry{FEP-Mathematical-Review}{article}{}
      \name{author}{4}{}{%
        {{hash=6ba2af6672c84ba8cffc8b86bc35d608}{%
           family={Buckley},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima L.},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=c1b5b32053d9b98890287559854c6bc0}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Chang\bibnamedelima Sub},
           giveni={C\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=1f6d0ed894e9e4e40438088b9585eac8}{%
           family={McGregor},
           familyi={M\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod}}}%
        {{hash=a18faa5d293b699968705a564971492b}{%
           family={Seth},
           familyi={S\bibinitperiod},
           given={Anil\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{79b1493ab9729517ef84ecf75d82779b}
      \strng{fullhash}{d6768cab4ac2fbb725f3f42aaa91b95e}
      \strng{bibnamehash}{79b1493ab9729517ef84ecf75d82779b}
      \strng{authorbibnamehash}{79b1493ab9729517ef84ecf75d82779b}
      \strng{authornamehash}{79b1493ab9729517ef84ecf75d82779b}
      \strng{authorfullhash}{d6768cab4ac2fbb725f3f42aaa91b95e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The ‘free energy principle’ (FEP) has been suggested to provide a unified theory of the brain, integrating data and theory relating to action, perception, and learning. The theory and implementation of the FEP combines insights from Helmholtzian ‘perception as inference’, machine learning theory, and statistical thermodynamics. Here, we provide a detailed mathematical evaluation of a suggested biologically plausible implementation of the FEP that has been widely used to develop the theory. Our objectives are (i) to describe within a single article the mathematical structure of this implementation of the FEP; (ii) provide a simple but complete agent-based model utilising the FEP and (iii) to disclose the assumption structure of this implementation of the FEP to help elucidate its significance for the brain sciences.}
      \field{issn}{0022-2496}
      \field{journaltitle}{Journal of Mathematical Psychology}
      \field{title}{The free energy principle for action and perception: A mathematical review}
      \field{volume}{81}
      \field{year}{2017}
      \field{pages}{55\bibrangedash 79}
      \range{pages}{25}
      \verb{doi}
      \verb https://doi.org/10.1016/j.jmp.2017.09.004
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0022249617300962
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0022249617300962
      \endverb
      \keyw{Free energy principle,Perception,Action,Inference,Bayesian brain,Agent-based model}
    \endentry
    \entry{Bayesian-Policy-Selection-AIF}{misc}{}
      \name{author}{5}{}{%
        {{hash=a9469e9b7223203fccc44acf37205929}{%
           family={Çatal},
           familyi={Ç\bibinitperiod},
           given={Ozan},
           giveni={O\bibinitperiod}}}%
        {{hash=b7d06c9b4d39365ac1da2ebaecdfa1d4}{%
           family={Nauta},
           familyi={N\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
        {{hash=7ae0249027282ce63a8b130db60b88f6}{%
           family={Verbelen},
           familyi={V\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=b205681adac9f09fac495059f6ece5f2}{%
           family={Simoens},
           familyi={S\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod}}}%
        {{hash=f3a7566cafe3d87f70b255c25b92611a}{%
           family={Dhoedt},
           familyi={D\bibinitperiod},
           given={Bart},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{699fb36c9052c496193e1600226b7edc}
      \strng{fullhash}{a27200328ae632cf52e87f4cb3ab9c43}
      \strng{bibnamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authorbibnamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authornamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authorfullhash}{a27200328ae632cf52e87f4cb3ab9c43}
      \field{extraname}{1}
      \field{sortinit}{Ç}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.LG}
      \field{eprinttype}{arXiv}
      \field{title}{Bayesian policy selection using active inference}
      \field{year}{2019}
      \verb{eprint}
      \verb 1904.08149
      \endverb
    \endentry
    \entry{Bayesian-Policy-Selection-Using-AIF}{misc}{}
      \name{author}{5}{}{%
        {{hash=a9469e9b7223203fccc44acf37205929}{%
           family={Çatal},
           familyi={Ç\bibinitperiod},
           given={Ozan},
           giveni={O\bibinitperiod}}}%
        {{hash=b7d06c9b4d39365ac1da2ebaecdfa1d4}{%
           family={Nauta},
           familyi={N\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
        {{hash=7ae0249027282ce63a8b130db60b88f6}{%
           family={Verbelen},
           familyi={V\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=b205681adac9f09fac495059f6ece5f2}{%
           family={Simoens},
           familyi={S\bibinitperiod},
           given={Pieter},
           giveni={P\bibinitperiod}}}%
        {{hash=f3a7566cafe3d87f70b255c25b92611a}{%
           family={Dhoedt},
           familyi={D\bibinitperiod},
           given={Bart},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{699fb36c9052c496193e1600226b7edc}
      \strng{fullhash}{a27200328ae632cf52e87f4cb3ab9c43}
      \strng{bibnamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authorbibnamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authornamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authorfullhash}{a27200328ae632cf52e87f4cb3ab9c43}
      \field{extraname}{2}
      \field{sortinit}{Ç}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.LG}
      \field{eprinttype}{arXiv}
      \field{title}{Bayesian policy selection using active inference}
      \field{year}{2019}
      \verb{eprint}
      \verb 1904.08149
      \endverb
    \endentry
    \entry{Learn-Gen-State-Space-Models-AIF}{article}{}
      \name{author}{5}{}{%
        {{hash=a9469e9b7223203fccc44acf37205929}{%
           family={Çatal},
           familyi={Ç\bibinitperiod},
           given={Ozan},
           giveni={O\bibinitperiod}}}%
        {{hash=891e91c3180a4ec158661bda6a2a12b3}{%
           family={Wauthier},
           familyi={W\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod}}}%
        {{hash=38266ac492939aa0c420eb536a242977}{%
           family={De\bibnamedelima Boom},
           familyi={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Cedric},
           giveni={C\bibinitperiod}}}%
        {{hash=7ae0249027282ce63a8b130db60b88f6}{%
           family={Verbelen},
           familyi={V\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=f3a7566cafe3d87f70b255c25b92611a}{%
           family={Dhoedt},
           familyi={D\bibinitperiod},
           given={Bart},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{699fb36c9052c496193e1600226b7edc}
      \strng{fullhash}{ff47c0df4cfe4280da02a0c506cae12a}
      \strng{bibnamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authorbibnamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authornamehash}{699fb36c9052c496193e1600226b7edc}
      \strng{authorfullhash}{ff47c0df4cfe4280da02a0c506cae12a}
      \field{extraname}{3}
      \field{sortinit}{Ç}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper we investigate the active inference framework as a means to enable autonomous behavior in artificial agents. Active inference is a theoretical framework underpinning the way organisms act and observe in the real world. In active inference, agents act in order to minimize their so called free energy, or prediction error. Besides being biologically plausible, active inference has been shown to solve hard exploration problems in various simulated environments. However, these simulations typically require handcrafting a generative model for the agent. Therefore we propose to use recent advances in deep artificial neural networks to learn generative state space models from scratch, using only observation-action sequences. This way we are able to scale active inference to new and challenging problem domains, whilst still building on the theoretical backing of the free energy principle. We validate our approach on the mountain car problem to illustrate that our learnt models can indeed trade-off instrumental value and ambiguity. Furthermore, we show that generative models can also be learnt using high-dimensional pixel observations, both in the OpenAI Gym car racing environment and a real-world robotic navigation task. Finally we show that active inference based policies are an order of magnitude more sample efficient than Deep Q Networks on RL tasks.}
      \field{issn}{1662-5188}
      \field{journaltitle}{Frontiers in Computational Neuroscience}
      \field{title}{Learning Generative State Space Models for Active Inference}
      \field{volume}{14}
      \field{year}{2020}
      \verb{doi}
      \verb 10.3389/fncom.2020.574372
      \endverb
      \verb{urlraw}
      \verb https://www.frontiersin.org/articles/10.3389/fncom.2020.574372
      \endverb
      \verb{url}
      \verb https://www.frontiersin.org/articles/10.3389/fncom.2020.574372
      \endverb
    \endentry
    \entry{RLflawed}{article}{}
      \name{author}{1}{}{%
        {{hash=cffdbdf7d0beb981d8bb8ea28506a4b2}{%
           family={Christiano},
           familyi={C\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{cffdbdf7d0beb981d8bb8ea28506a4b2}
      \strng{fullhash}{cffdbdf7d0beb981d8bb8ea28506a4b2}
      \strng{bibnamehash}{cffdbdf7d0beb981d8bb8ea28506a4b2}
      \strng{authorbibnamehash}{cffdbdf7d0beb981d8bb8ea28506a4b2}
      \strng{authornamehash}{cffdbdf7d0beb981d8bb8ea28506a4b2}
      \strng{authorfullhash}{cffdbdf7d0beb981d8bb8ea28506a4b2}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{The Gradient}
      \field{title}{Why Reinforcement Learning is Flawed}
      \field{year}{2019}
      \verb{urlraw}
      \verb https://thegradient.pub/why-rl-is-flawed/
      \endverb
      \verb{url}
      \verb https://thegradient.pub/why-rl-is-flawed/
      \endverb
    \endentry
    \entry{Factor-Graph-Approach-Automated-Design-Bayesian-Algos}{article}{}
      \name{author}{3}{}{%
        {{hash=4b41e1d66ebdde7171f697bf9892597c}{%
           family={Cox},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
        {{hash=013ae0ec21570cef47f38a73391b6b1d}{%
           family={Laar},
           familyi={L\bibinitperiod},
           given={Thijs},
           giveni={T\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=2caeea1b18c3a6d6099b66a5232eb983}{%
           family={Vries},
           familyi={V\bibinitperiod},
           given={Bert},
           giveni={B\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Elsevier {BV}}%
      }
      \strng{namehash}{5162e215c531d8e582746526d63ec292}
      \strng{fullhash}{5162e215c531d8e582746526d63ec292}
      \strng{bibnamehash}{5162e215c531d8e582746526d63ec292}
      \strng{authorbibnamehash}{5162e215c531d8e582746526d63ec292}
      \strng{authornamehash}{5162e215c531d8e582746526d63ec292}
      \strng{authorfullhash}{5162e215c531d8e582746526d63ec292}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Journal of Approximate Reasoning}
      \field{month}{01}
      \field{title}{A factor graph approach to automated design of Bayesian signal processing algorithms}
      \field{volume}{104}
      \field{year}{2019}
      \field{pages}{185\bibrangedash 204}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1016/j.ijar.2018.11.002
      \endverb
    \endentry
    \entry{AIF-Discrete-Action-Spaces-Synthesis}{article}{}
      \name{author}{6}{}{%
        {{hash=332cb0e034bc330deba64ea078b1d415}{%
           family={{Da Costa}},
           familyi={D\bibinitperiod},
           given={Lancelot},
           giveni={L\bibinitperiod}}}%
        {{hash=11ecca46a14363f21a56a51e1cb6c0ad}{%
           family={Parr},
           familyi={P\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=e667ee3bbe292c32c024d533e2410a71}{%
           family={Sajid},
           familyi={S\bibinitperiod},
           given={Noor},
           giveni={N\bibinitperiod}}}%
        {{hash=fbc1874ff3ffd381916e05dce28b4b8b}{%
           family={Veselic},
           familyi={V\bibinitperiod},
           given={Sebastijan},
           giveni={S\bibinitperiod}}}%
        {{hash=00573704568048fe88f8a672331861e4}{%
           family={Neacsu},
           familyi={N\bibinitperiod},
           given={Victorita},
           giveni={V\bibinitperiod}}}%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{fullhash}{4c74fee4d74e85a764da54e98c8ba6ac}
      \strng{bibnamehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{authorbibnamehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{authornamehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{authorfullhash}{4c74fee4d74e85a764da54e98c8ba6ac}
      \field{extraname}{1}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.}
      \field{issn}{0022-2496}
      \field{journaltitle}{Journal of Mathematical Psychology}
      \field{title}{Active inference on discrete state-spaces: A synthesis}
      \field{volume}{99}
      \field{year}{2020}
      \field{pages}{102447}
      \range{pages}{1}
      \verb{doi}
      \verb https://doi.org/10.1016/j.jmp.2020.102447
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0022249620300857
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0022249620300857
      \endverb
      \keyw{Active inference,Free energy principle,Process theory,Variational Bayesian inference,Markov decision process,Mathematical review}
    \endentry
    \entry{Relationship-Dynamic-Programming-AIF}{unknown}{}
      \name{author}{5}{}{%
        {{hash=332cb0e034bc330deba64ea078b1d415}{%
           family={Da\bibnamedelima Costa},
           familyi={D\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Lancelot},
           giveni={L\bibinitperiod}}}%
        {{hash=e667ee3bbe292c32c024d533e2410a71}{%
           family={Sajid},
           familyi={S\bibinitperiod},
           given={Noor},
           giveni={N\bibinitperiod}}}%
        {{hash=11ecca46a14363f21a56a51e1cb6c0ad}{%
           family={Parr},
           familyi={P\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
        {{hash=2375765385b5498bd2826de02ade4c7d}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{fullhash}{5682a89f6b7052f55a788db43cd583bf}
      \strng{bibnamehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{authorbibnamehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{authornamehash}{d1691ea07c6ae43b2eb1ebe845a987b4}
      \strng{authorfullhash}{5682a89f6b7052f55a788db43cd583bf}
      \field{extraname}{2}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{09}
      \field{title}{The relationship between dynamic programming and active inference: the discrete, finite-horizon case}
      \field{year}{2020}
    \endentry
    \entry{RL-Real-World-Challenges}{article}{}
      \name{author}{7}{}{%
        {{hash=1e75a9df444c5ef79ce4db4c8dd76ddc}{%
           family={Dulac-Arnold},
           familyi={D\bibinithyphendelim A\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod}}}%
        {{hash=13cc3695358a6c91515c272e1c4f8096}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Nir},
           giveni={N\bibinitperiod}}}%
        {{hash=d53f04077b0434704ab60a1a7bc58a71}{%
           family={Mankowitz},
           familyi={M\bibinitperiod},
           given={Daniel\bibnamedelima J.},
           giveni={D\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=3b3012e4ca17639feb14b7bd7910c117}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Jerry},
           giveni={J\bibinitperiod}}}%
        {{hash=a58a4770e2e7fd035b28393767299b9e}{%
           family={Paduraru},
           familyi={P\bibinitperiod},
           given={Cosmin},
           giveni={C\bibinitperiod}}}%
        {{hash=1684b384584547bc4441639093dc0533}{%
           family={Gowal},
           familyi={G\bibinitperiod},
           given={Sven},
           giveni={S\bibinitperiod}}}%
        {{hash=c637e4ed3fcc395fa56d8aab57126d4d}{%
           family={Hester},
           familyi={H\bibinitperiod},
           given={Todd},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{f365a2cfe7993eced9cc5ffa3d632001}
      \strng{fullhash}{c1b66da100ed35228a7a909ed778aed6}
      \strng{bibnamehash}{f365a2cfe7993eced9cc5ffa3d632001}
      \strng{authorbibnamehash}{f365a2cfe7993eced9cc5ffa3d632001}
      \strng{authornamehash}{f365a2cfe7993eced9cc5ffa3d632001}
      \strng{authorfullhash}{c1b66da100ed35228a7a909ed778aed6}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Reinforcement learning (RL) has proven its worth in a series of artificial domains, and is beginning to show some successes in real-world scenarios. However, much of the research advances in RL are hard to leverage in real-world systems due to a series of assumptions that are rarely satisfied in practice. In this work, we identify and formalize a series of independent challenges that embody the difficulties that must be addressed for RL to be commonly deployed in real-world systems. For each challenge, we define it formally in the context of a Markov Decision Process, analyze the effects of the challenge on state-of-the-art learning algorithms, and present some existing attempts at tackling it. We believe that an approach that addresses our set of proposed challenges would be readily deployable in a large number of real world problems. Our proposed challenges are implemented in a suite of continuous control environments called realworldrl-suite which we propose an as an open-source benchmark.}
      \field{issn}{1573-0565}
      \field{journaltitle}{Machine Learning}
      \field{month}{9}
      \field{number}{9}
      \field{title}{Challenges of real-world reinforcement learning: definitions, benchmarks and analysis}
      \field{volume}{110}
      \field{year}{2021}
      \field{pages}{2419\bibrangedash 2468}
      \range{pages}{50}
      \verb{doi}
      \verb 10.1007/s10994-021-05961-4
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s10994-021-05961-4
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s10994-021-05961-4
      \endverb
    \endentry
    \entry{Codes-on-Graphs}{article}{}
      \name{author}{1}{}{%
        {{hash=1c58ad3962bf89e08d33c9278595f3c6}{%
           family={Forney},
           familyi={F\bibinitperiod},
           given={G.D.},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{1c58ad3962bf89e08d33c9278595f3c6}
      \strng{fullhash}{1c58ad3962bf89e08d33c9278595f3c6}
      \strng{bibnamehash}{1c58ad3962bf89e08d33c9278595f3c6}
      \strng{authorbibnamehash}{1c58ad3962bf89e08d33c9278595f3c6}
      \strng{authornamehash}{1c58ad3962bf89e08d33c9278595f3c6}
      \strng{authorfullhash}{1c58ad3962bf89e08d33c9278595f3c6}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Transactions on Information Theory}
      \field{number}{2}
      \field{title}{Codes on graphs: normal realizations}
      \field{volume}{47}
      \field{year}{2001}
      \field{pages}{520\bibrangedash 548}
      \range{pages}{29}
      \verb{doi}
      \verb 10.1109/18.910573
      \endverb
    \endentry
    \entry{Action-Behaviour-FE}{article}{}
      \name{author}{4}{}{%
        {{hash=6bb644f22d1a01d9ea99fa3f285e0e15}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={K},
           giveni={K\bibinitperiod}}}%
        {{hash=f2f55a21fe7f17b57c5b9d6678496ba0}{%
           family={Daunizeau},
           familyi={D\bibinitperiod},
           given={J},
           giveni={J\bibinitperiod}}}%
        {{hash=5436e33cae5d72aa0e98897adbe7a678}{%
           family={Kilner},
           familyi={K\bibinitperiod},
           given={J},
           giveni={J\bibinitperiod}}}%
        {{hash=69e1fbf549a17e40a4147441a96abe7a}{%
           family={Kiebel},
           familyi={K\bibinitperiod},
           given={S},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{6b3b7568c58d0d120cdc6b7fc0f1bdfe}
      \strng{fullhash}{5ddc0f220a3f70c87e1fe619c017d196}
      \strng{bibnamehash}{6b3b7568c58d0d120cdc6b7fc0f1bdfe}
      \strng{authorbibnamehash}{6b3b7568c58d0d120cdc6b7fc0f1bdfe}
      \strng{authornamehash}{6b3b7568c58d0d120cdc6b7fc0f1bdfe}
      \strng{authorfullhash}{5ddc0f220a3f70c87e1fe619c017d196}
      \field{extraname}{1}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Biological cybernetics}
      \field{number}{3}
      \field{title}{Action and behavior: a free-energy formulation}
      \field{volume}{102}
      \field{year}{2010}
      \field{pages}{227\bibrangedash 260}
      \range{pages}{34}
      \verb{doi}
      \verb 10.1007/s00422-010-0364-z
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s00422-010-0364-z
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s00422-010-0364-z
      \endverb
    \endentry
    \entry{Life-As-We-Know-It}{article}{}
      \name{author}{1}{}{%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{fullhash}{9f452a84796a900973333b32a5f8bc61}
      \strng{bibnamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authorbibnamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authornamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authorfullhash}{9f452a84796a900973333b32a5f8bc61}
      \field{extraname}{1}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents a heuristic proof (and simulations of a primordial soup) suggesting that life—or biological self-organization—is an inevitable and emergent property of any (ergodic) random dynamical system that possesses a Markov blanket. This conclusion is based on the following arguments: if the coupling among an ensemble of dynamical systems is mediated by short-range forces, then the states of remote systems must be conditionally independent. These independencies induce a Markov blanket that separates internal and external states in a statistical sense. The existence of a Markov blanket means that internal states will appear to minimize a free energy functional of the states of their Markov blanket. Crucially, this is the same quantity that is optimized in Bayesian inference. Therefore, the internal states (and their blanket) will appear to engage in active Bayesian inference. In other words, they will appear to model—and act on—their world to preserve their functional and structural integrity, leading to homoeostasis and a simple form of autopoiesis.}
      \field{journaltitle}{Journal of The Royal Society Interface}
      \field{number}{86}
      \field{title}{Life as we know it}
      \field{volume}{10}
      \field{year}{2013}
      \field{pages}{20130475}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1098/rsif.2013.0475
      \endverb
      \verb{eprint}
      \verb https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2013.0475
      \endverb
      \verb{urlraw}
      \verb https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2013.0475
      \endverb
      \verb{url}
      \verb https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2013.0475
      \endverb
    \endentry
    \entry{FEP-Rough-Guide-Brain}{online}{}
      \name{author}{1}{}{%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{fullhash}{9f452a84796a900973333b32a5f8bc61}
      \strng{bibnamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authorbibnamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authornamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authorfullhash}{9f452a84796a900973333b32a5f8bc61}
      \field{extraname}{2}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{The free-energy principle: a rough guide to the brain?}
      \field{year}{2009}
      \verb{urlraw}
      \verb https://doi.org/10.1016/j.tics.2009.04.005
      \endverb
      \verb{url}
      \verb https://doi.org/10.1016/j.tics.2009.04.005
      \endverb
    \endentry
    \entry{FEP-Unified-Brain-Theory}{article}{}
      \name{author}{1}{}{%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{fullhash}{9f452a84796a900973333b32a5f8bc61}
      \strng{bibnamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authorbibnamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authornamehash}{9f452a84796a900973333b32a5f8bc61}
      \strng{authorfullhash}{9f452a84796a900973333b32a5f8bc61}
      \field{extraname}{3}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Adaptive agents must occupy a limited repertoire of states and therefore minimize the long-term average of surprise associated with sensory exchanges with the world. Minimizing surprise enables them to resist a natural tendency to disorder.Surprise rests on predictions about sensations, which depend on an internal generative model of the world. Although surprise cannot be measured directly, a free-energy bound on surprise can be, suggesting that agents minimize free energy by changing their predictions (perception) or by changing the predicted sensory inputs (action).Perception optimizes predictions by minimizing free energy with respect to synaptic activity (perceptual inference), efficacy (learning and memory) and gain (attention and salience). This furnishes Bayes-optimal (probabilistic) representations of what caused sensations (providing a link to the Bayesian brain hypothesis).Bayes-optimal perception is mathematically equivalent to predictive coding and maximizing the mutual information between sensations and the representations of their causes. This is a probabilistic generalization of the principle of efficient coding (the infomax principle) or the minimum-redundancy principle.Learning under the free-energy principle can be formulated in terms of optimizing the connection strengths in hierarchical models of the sensorium. This rests on associative plasticity to encode causal regularities and appeals to the same synaptic mechanisms as those underlying cell assembly formation.Action under the free-energy principle reduces to suppressing sensory prediction errors that depend on predicted (expected or desired) movement trajectories. This provides a simple account of motor control, in which action is enslaved by perceptual (proprioceptive) predictions.Perceptual predictions rest on prior expectations about the trajectory or movement through the agent's state space. These priors can be acquired (as empirical priors during hierarchical inference) or they can be innate (epigenetic) and therefore subject to selective pressure.Predicted motion or state transitions realized by action correspond to policies in optimal control theory and reinforcement learning. In this context, value is inversely proportional to surprise (and implicitly free energy), and rewards correspond to innate priors that constrain policies.}
      \field{issn}{1471-0048}
      \field{journaltitle}{Nature Reviews Neuroscience}
      \field{month}{2}
      \field{number}{2}
      \field{title}{The free-energy principle: a unified brain theory?}
      \field{volume}{11}
      \field{year}{2010}
      \field{pages}{127\bibrangedash 138}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1038/nrn2787
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1038/nrn2787
      \endverb
      \verb{url}
      \verb https://doi.org/10.1038/nrn2787
      \endverb
    \endentry
    \entry{A_FEP_For_The_Brain}{article}{}
      \name{author}{3}{}{%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
        {{hash=b757d0ab7f8fba305197fe5782f69a40}{%
           family={Kilner},
           familyi={K\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=e8c32a428244daba919a10eb36879a72}{%
           family={Harrison},
           familyi={H\bibinitperiod},
           given={Lee},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{5706deb9ee6c19e729be91d04b89629c}
      \strng{fullhash}{5706deb9ee6c19e729be91d04b89629c}
      \strng{bibnamehash}{5706deb9ee6c19e729be91d04b89629c}
      \strng{authorbibnamehash}{5706deb9ee6c19e729be91d04b89629c}
      \strng{authornamehash}{5706deb9ee6c19e729be91d04b89629c}
      \strng{authorfullhash}{5706deb9ee6c19e729be91d04b89629c}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{By formulating Helmholtz’s ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system’s state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure.}
      \field{issn}{0928-4257}
      \field{journaltitle}{Journal of Physiology-Paris}
      \field{note}{Theoretical and Computational Neuroscience: Understanding Brain Functions}
      \field{number}{1}
      \field{title}{A free energy principle for the brain}
      \field{volume}{100}
      \field{year}{2006}
      \field{pages}{70\bibrangedash 87}
      \range{pages}{18}
      \verb{doi}
      \verb https://doi.org/10.1016/j.jphysparis.2006.10.001
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S092842570600060X
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S092842570600060X
      \endverb
      \keyw{Variational Bayes,Free energy,Inference,Perception,Action,Learning,Attention,Selection,Hierarchical}
    \endentry
    \entry{AIF-Epistemic-Value}{article}{}
      \name{author}{6}{}{%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
        {{hash=103c6f1e922e29f43590be466a0cb206}{%
           family={Rigoli},
           familyi={R\bibinitperiod},
           given={Francesco},
           giveni={F\bibinitperiod}}}%
        {{hash=fc4575c484ed62fef0505e03b18df463}{%
           family={Ognibene},
           familyi={O\bibinitperiod},
           given={Dimitri},
           giveni={D\bibinitperiod}}}%
        {{hash=d531a432bbd0476710542d1c3b647224}{%
           family={Mathys},
           familyi={M\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=9ed05519a8c0ad06d15ad12e8f93ffea}{%
           family={Fitzgerald},
           familyi={F\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=a407d9f6bc90219c5764e676c5b8caa7}{%
           family={Pezzulo},
           familyi={P\bibinitperiod},
           given={Giovanni},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Routledge}%
      }
      \strng{namehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{fullhash}{4dc2bf1cdfb9ed9f94125cbf6d9f95ba}
      \strng{bibnamehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{authorbibnamehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{authornamehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{authorfullhash}{4dc2bf1cdfb9ed9f94125cbf6d9f95ba}
      \field{extraname}{2}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Cognitive Neuroscience}
      \field{note}{PMID: 25689102}
      \field{number}{4}
      \field{title}{Active inference and epistemic value}
      \field{volume}{6}
      \field{year}{2015}
      \field{pages}{187\bibrangedash 214}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1080/17588928.2015.1020053
      \endverb
      \verb{eprint}
      \verb https://doi.org/10.1080/17588928.2015.1020053
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1080/17588928.2015.1020053
      \endverb
      \verb{url}
      \verb https://doi.org/10.1080/17588928.2015.1020053
      \endverb
    \endentry
    \entry{Generalized-Filtering}{article}{}
      \name{author}{4}{}{%
        {{hash=9f452a84796a900973333b32a5f8bc61}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl},
           giveni={K\bibinitperiod}}}%
        {{hash=4f9f1e677c3b173e5723cce467a7621c}{%
           family={Stephan},
           familyi={S\bibinitperiod},
           given={Klaas},
           giveni={K\bibinitperiod}}}%
        {{hash=b29e9e747205f1b025dc145e440698b7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Baojuan},
           giveni={B\bibinitperiod}}}%
        {{hash=8d47f509e61c9543876ac29ea6eff7ea}{%
           family={Daunizeau},
           familyi={D\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Hindawi Publishing Corporation}%
      }
      \strng{namehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{fullhash}{1ba7dad87dee2906e5a604c5702e1381}
      \strng{bibnamehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{authorbibnamehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{authornamehash}{a5aa6cc9fa51d6be7eef2a1be62bf301}
      \strng{authorfullhash}{1ba7dad87dee2906e5a604c5702e1381}
      \field{extraname}{3}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe a Bayesian filtering scheme for nonlinear state-space models in continuous time. This scheme is called Generalised Filtering and furnishes posterior (conditional) densities on hidden states and unknown parameters generating observed data. Crucially, the scheme operates online, assimilating data to optimize the conditional density on time-varying states and time-invariant parameters. In contrast to Kalman and Particle smoothing, Generalised Filtering does not require a backwards pass. In contrast to variational schemes, it does not assume conditional independence between the states and parameters. Generalised Filtering optimises the conditional density with respect to a free-energy bound on the model's log-evidence. This optimisation uses the generalised motion of hidden states and parameters, under the prior assumption that the motion of the parameters is small. We describe the scheme, present comparative evaluations with a fixed-form variational version, and conclude with an illustrative application to a nonlinear state-space model of brain imaging time-series.}
      \field{issn}{1024-123X}
      \field{journaltitle}{Mathematical Problems in Engineering}
      \field{month}{6}
      \field{title}{Generalised Filtering}
      \field{volume}{2010}
      \field{year}{2010}
      \field{pages}{621670}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1155/2010/621670
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1155/2010/621670
      \endverb
      \verb{url}
      \verb https://doi.org/10.1155/2010/621670
      \endverb
    \endentry
    \entry{RL-or-AIF}{article}{}
      \name{author}{3}{}{%
        {{hash=558c08870d21f7acad878d94e125a377}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl\bibnamedelima J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=8d47f509e61c9543876ac29ea6eff7ea}{%
           family={Daunizeau},
           familyi={D\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=2f90964b242f5332c487e701a6d5f780}{%
           family={Kiebel},
           familyi={K\bibinitperiod},
           given={Stefan\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Public Library of Science}%
      }
      \strng{namehash}{7cf5308d50e8287a641b45d56c82abf4}
      \strng{fullhash}{7cf5308d50e8287a641b45d56c82abf4}
      \strng{bibnamehash}{7cf5308d50e8287a641b45d56c82abf4}
      \strng{authorbibnamehash}{7cf5308d50e8287a641b45d56c82abf4}
      \strng{authornamehash}{7cf5308d50e8287a641b45d56c82abf4}
      \strng{authorfullhash}{7cf5308d50e8287a641b45d56c82abf4}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper questions the need for reinforcement learning or control theory when optimising behaviour. We show that it is fairly simple to teach an agent complicated and adaptive behaviours using a free-energy formulation of perception. In this formulation, agents adjust their internal states and sampling of the environment to minimize their free-energy. Such agents learn causal structure in the environment and sample it in an adaptive and self-supervised fashion. This results in behavioural policies that reproduce those optimised by reinforcement learning and dynamic programming. Critically, we do not need to invoke the notion of reward, value or utility. We illustrate these points by solving a benchmark problem in dynamic programming; namely the mountain-car problem, using active perception or inference under the free-energy principle. The ensuing proof-of-concept may be important because the free-energy formulation furnishes a unified account of both action and perception and may speak to a reappraisal of the role of dopamine in the brain.}
      \field{journaltitle}{PLOS ONE}
      \field{month}{07}
      \field{number}{7}
      \field{title}{Reinforcement Learning or Active Inference?}
      \field{volume}{4}
      \field{year}{2009}
      \field{pages}{1\bibrangedash 13}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1371/journal.pone.0006421
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1371/journal.pone.0006421
      \endverb
      \verb{url}
      \verb https://doi.org/10.1371/journal.pone.0006421
      \endverb
    \endentry
    \entry{DEEP-AIF-For-POMDPs}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=06c37bfed052127a76e6474ca3f49f37}{%
           family={Himst},
           familyi={H\bibinitperiod},
           given={Otto},
           giveni={O\bibinitperiod},
           prefix={van\bibnamedelima der},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=cf067a7818cf1d885b2180516a8afe69}{%
           family={Lanillos},
           familyi={L\bibinitperiod},
           given={Pablo},
           giveni={P\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=7ae0249027282ce63a8b130db60b88f6}{%
           family={Verbelen},
           familyi={V\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=cf067a7818cf1d885b2180516a8afe69}{%
           family={Lanillos},
           familyi={L\bibinitperiod},
           given={Pablo},
           giveni={P\bibinitperiod}}}%
        {{hash=6ba2af6672c84ba8cffc8b86bc35d608}{%
           family={Buckley},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima L.},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=38266ac492939aa0c420eb536a242977}{%
           family={De\bibnamedelima Boom},
           familyi={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Cedric},
           giveni={C\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{a3922fc2b7d1d8fa590d9e392c28b5c9}
      \strng{fullhash}{a3922fc2b7d1d8fa590d9e392c28b5c9}
      \strng{bibnamehash}{a3922fc2b7d1d8fa590d9e392c28b5c9}
      \strng{authorbibnamehash}{a3922fc2b7d1d8fa590d9e392c28b5c9}
      \strng{authornamehash}{a3922fc2b7d1d8fa590d9e392c28b5c9}
      \strng{authorfullhash}{a3922fc2b7d1d8fa590d9e392c28b5c9}
      \strng{editorbibnamehash}{8b15176a83e57ea480f936b194676b3b}
      \strng{editornamehash}{8b15176a83e57ea480f936b194676b3b}
      \strng{editorfullhash}{c0f0fffcf97521c4f2c33afa1538123d}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep active inference has been proposed as a scalable approach to perception and action that deals with large policy and state spaces. However, current models are limited to fully observable domains. In this paper, we describe a deep active inference model that can learn successful policies directly from high-dimensional sensory inputs. The deep learning architecture optimizes a variant of the expected free energy and encodes the continuous state representation by means of a variational autoencoder. We show, in the OpenAI benchmark, that our approach has comparable or better performance than deep Q-learning, a state-of-the-art deep reinforcement learning algorithm.}
      \field{booktitle}{Active Inference}
      \field{isbn}{978-3-030-64919-7}
      \field{title}{Deep Active Inference for Partially Observable MDPs}
      \field{year}{2020}
      \field{pages}{61\bibrangedash 71}
      \range{pages}{11}
    \endentry
    \entry{The-Bayesian-Brain}{article}{}
      \name{author}{2}{}{%
        {{hash=ff12f66322a37f127d33e91746d3577f}{%
           family={Knill},
           familyi={K\bibinitperiod},
           given={David\bibnamedelima C.},
           giveni={D\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=330aaa9645b14ab62852c0a3bb1c7a9a}{%
           family={Pouget},
           familyi={P\bibinitperiod},
           given={Alexandre},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{3c7746623d64cdf7259e30d04657573c}
      \strng{fullhash}{3c7746623d64cdf7259e30d04657573c}
      \strng{bibnamehash}{3c7746623d64cdf7259e30d04657573c}
      \strng{authorbibnamehash}{3c7746623d64cdf7259e30d04657573c}
      \strng{authornamehash}{3c7746623d64cdf7259e30d04657573c}
      \strng{authorfullhash}{3c7746623d64cdf7259e30d04657573c}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are ‘Bayes' optimal’. This leads to the ‘Bayesian coding hypothesis’: that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.}
      \field{issn}{0166-2236}
      \field{journaltitle}{Trends in Neurosciences}
      \field{number}{12}
      \field{title}{The Bayesian brain: the role of uncertainty in neural coding and computation}
      \field{volume}{27}
      \field{year}{2004}
      \field{pages}{712\bibrangedash 719}
      \range{pages}{8}
      \verb{doi}
      \verb https://doi.org/10.1016/j.tins.2004.10.007
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0166223604003352
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0166223604003352
      \endverb
    \endentry
    \entry{Message-Passing-Perspective-Planning-Under-AIF}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=3f9715382a039e62fed7ea317bf9c852}{%
           family={Koudahl},
           familyi={K\bibinitperiod},
           given={Magnus},
           giveni={M\bibinitperiod}}}%
        {{hash=6ba2af6672c84ba8cffc8b86bc35d608}{%
           family={Buckley},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima L.},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=2caeea1b18c3a6d6099b66a5232eb983}{%
           family={Vries},
           familyi={V\bibinitperiod},
           given={Bert},
           giveni={B\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \name{editor}{7}{}{%
        {{hash=6ba2af6672c84ba8cffc8b86bc35d608}{%
           family={Buckley},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima L.},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=c720fdd47221dd1dac7f176bb824cd81}{%
           family={Cialfi},
           familyi={C\bibinitperiod},
           given={Daniela},
           giveni={D\bibinitperiod}}}%
        {{hash=cf067a7818cf1d885b2180516a8afe69}{%
           family={Lanillos},
           familyi={L\bibinitperiod},
           given={Pablo},
           giveni={P\bibinitperiod}}}%
        {{hash=ea66ff5ca9929c905754cf378e4fb96c}{%
           family={Ramstead},
           familyi={R\bibinitperiod},
           given={Maxwell},
           giveni={M\bibinitperiod}}}%
        {{hash=e667ee3bbe292c32c024d533e2410a71}{%
           family={Sajid},
           familyi={S\bibinitperiod},
           given={Noor},
           giveni={N\bibinitperiod}}}%
        {{hash=1412f70278a2490451d2ec6a99ec62f2}{%
           family={Shimazaki},
           familyi={S\bibinitperiod},
           given={Hideaki},
           giveni={H\bibinitperiod}}}%
        {{hash=7ae0249027282ce63a8b130db60b88f6}{%
           family={Verbelen},
           familyi={V\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer Nature Switzerland}%
      }
      \strng{namehash}{8ebba9d2eccf7488d75764ba52e6c8ae}
      \strng{fullhash}{8ebba9d2eccf7488d75764ba52e6c8ae}
      \strng{bibnamehash}{8ebba9d2eccf7488d75764ba52e6c8ae}
      \strng{authorbibnamehash}{8ebba9d2eccf7488d75764ba52e6c8ae}
      \strng{authornamehash}{8ebba9d2eccf7488d75764ba52e6c8ae}
      \strng{authorfullhash}{8ebba9d2eccf7488d75764ba52e6c8ae}
      \strng{editorbibnamehash}{79b1493ab9729517ef84ecf75d82779b}
      \strng{editornamehash}{79b1493ab9729517ef84ecf75d82779b}
      \strng{editorfullhash}{f777a4f7fd663adb6f88390eb6a8b03d}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a message passing interpretation of planning under Active Inference. Specifically, we show how the Active Inference planning procedure can be broken into a (partial) message passing sweep over a graph, followed by local computations of a cost functional (the Expected Free Energy). Using Forney-style Factor Graphs, we then proceed to show how one can derive novel planning schemes by local changes to the underlying graph and message passing schedule. We illustrate this by first isolating the ``sophisticated'' aspect of Sophisticated Inference and then proposing a novel planning algorithm through combining the sophisticated update mechanism with a different message passing schedule. Our main contribution is a modular view of planning under Active Inference that can serve as a framework for both understanding existing algorithms, deriving new ones and extending the class of models that are amenable to Active Inference. Approaching Active Inference from a message passing perspective also shows how it can be efficiently implemented using off-the-shelf probabilistic programming software, broadening the class of models available to researchers and practitioners.}
      \field{booktitle}{Active Inference}
      \field{isbn}{978-3-031-28719-0}
      \field{title}{A Message Passing Perspective on Planning Under Active Inference}
      \field{year}{2023}
      \field{pages}{319\bibrangedash 327}
      \range{pages}{9}
    \endentry
    \entry{Simulating-AIF-By-Message-Passing}{article}{}
      \name{author}{2}{}{%
        {{hash=5c38457efdb1b50d60a99a887eec33e1}{%
           family={Laar},
           familyi={L\bibinitperiod},
           given={Thijs\bibnamedelima W.},
           giveni={T\bibinitperiod\bibinitdelim W\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=2caeea1b18c3a6d6099b66a5232eb983}{%
           family={Vries},
           familyi={V\bibinitperiod},
           given={Bert},
           giveni={B\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
      }
      \strng{namehash}{cbeda3265f27ddc63a736bd502adb582}
      \strng{fullhash}{cbeda3265f27ddc63a736bd502adb582}
      \strng{bibnamehash}{cbeda3265f27ddc63a736bd502adb582}
      \strng{authorbibnamehash}{cbeda3265f27ddc63a736bd502adb582}
      \strng{authornamehash}{cbeda3265f27ddc63a736bd502adb582}
      \strng{authorfullhash}{cbeda3265f27ddc63a736bd502adb582}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The free energy principle (FEP) offers a variational calculus-based description for how biological agents persevere through interactions with their environment. Active inference (AI) is a corollary of the FEP, which states that biological agents act to fulfill prior beliefs about preferred future observations (target priors). Purposeful behavior then results from variational free energy minimization with respect to a generative model of the environment with included target priors. However, manual derivations for free energy minimizing algorithms on custom dynamic models can become tedious and error-prone. While probabilistic programming (PP) techniques enable automatic derivation of inference algorithms on free-form models, full automation of AI requires specialized tools for inference on dynamic models, together with the description of an experimental protocol that governs the interaction between the agent and its simulated environment. The contributions of the present paper are two-fold. Firstly, we illustrate how AI can be automated with the use of ForneyLab, a recent PP toolbox that specializes in variational inference on flexibly definable dynamic models. More specifically, we describe AI agents in a dynamic environment as probabilistic state space models (SSM) and perform inference for perception and control in these agents by message passing on a factor graph representation of the SSM. Secondly, we propose a formal experimental protocol for simulated AI. We exemplify how this protocol leads to goal-directed behavior for flexibly definable AI agents in two classical RL examples, namely the Bayesian thermostat and the mountain car parking problems.}
      \field{issn}{2296-9144}
      \field{journaltitle}{Frontiers in Robotics and AI}
      \field{title}{Simulating Active Inference Processes by Message Passing}
      \field{volume}{6}
      \field{year}{2019}
      \verb{doi}
      \verb 10.3389/frobt.2019.00020
      \endverb
      \verb{urlraw}
      \verb https://www.frontiersin.org/articles/10.3389/frobt.2019.00020
      \endverb
      \verb{url}
      \verb https://www.frontiersin.org/articles/10.3389/frobt.2019.00020
      \endverb
    \endentry
    \entry{Intro-to-Factor-Graphs}{article}{}
      \name{author}{1}{}{%
        {{hash=db2f8600c0724792e0d3db19774a9595}{%
           family={Loeliger},
           familyi={L\bibinitperiod},
           given={H.-A.},
           giveni={H\bibinithyphendelim A\bibinitperiod}}}%
      }
      \strng{namehash}{db2f8600c0724792e0d3db19774a9595}
      \strng{fullhash}{db2f8600c0724792e0d3db19774a9595}
      \strng{bibnamehash}{db2f8600c0724792e0d3db19774a9595}
      \strng{authorbibnamehash}{db2f8600c0724792e0d3db19774a9595}
      \strng{authornamehash}{db2f8600c0724792e0d3db19774a9595}
      \strng{authorfullhash}{db2f8600c0724792e0d3db19774a9595}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{IEEE Signal Processing Magazine}
      \field{number}{1}
      \field{title}{An introduction to factor graphs}
      \field{volume}{21}
      \field{year}{2004}
      \field{pages}{28\bibrangedash 41}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/MSP.2004.1267047
      \endverb
    \endentry
    \entry{Combine-Info-Seek-Explore-and-Reward-Maximization-Under-POMDP}{misc}{}
      \name{author}{2}{}{%
        {{hash=08f1ffc88f29ec23ea97a8358f88d017}{%
           family={Malekzadeh},
           familyi={M\bibinitperiod},
           given={Parvin},
           giveni={P\bibinitperiod}}}%
        {{hash=1435e45c2fdb83b800bebbba942ca920}{%
           family={Plataniotis},
           familyi={P\bibinitperiod},
           given={Konstantinos\bibnamedelima N.},
           giveni={K\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \strng{namehash}{fce8d252de4e2a720de1897db6cbd4d5}
      \strng{fullhash}{fce8d252de4e2a720de1897db6cbd4d5}
      \strng{bibnamehash}{fce8d252de4e2a720de1897db6cbd4d5}
      \strng{authorbibnamehash}{fce8d252de4e2a720de1897db6cbd4d5}
      \strng{authornamehash}{fce8d252de4e2a720de1897db6cbd4d5}
      \strng{authorfullhash}{fce8d252de4e2a720de1897db6cbd4d5}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.LG}
      \field{eprinttype}{arXiv}
      \field{title}{Combining information-seeking exploration and reward maximization: Unified inference on continuous state and action spaces under partial observability}
      \field{year}{2022}
      \verb{eprint}
      \verb 2212.07946
      \endverb
    \endentry
    \entry{Contrastive-AIF}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=f5f328ed70c8b2dfc4b2eb2d82372eec}{%
           family={Mazzaglia},
           familyi={M\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
        {{hash=7ae0249027282ce63a8b130db60b88f6}{%
           family={Verbelen},
           familyi={V\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=f3a7566cafe3d87f70b255c25b92611a}{%
           family={Dhoedt},
           familyi={D\bibinitperiod},
           given={Bart},
           giveni={B\bibinitperiod}}}%
      }
      \name{editor}{5}{}{%
        {{hash=6cb5af0e649387de5bbfdb150cc7a786}{%
           family={Ranzato},
           familyi={R\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=02854da982edf66ffa27f4fc1c738779}{%
           family={Beygelzimer},
           familyi={B\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
        {{hash=5e4dc483044b6dbd4496a818b8b6c67a}{%
           family={Dauphin},
           familyi={D\bibinitperiod},
           given={Y.},
           giveni={Y\bibinitperiod}}}%
        {{hash=12f9558e0c25864defe6eaed94a9011b}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={P.S.},
           giveni={P\bibinitperiod}}}%
        {{hash=3d379bd6370f69ebc79dc5337ed96d13}{%
           family={Vaughan},
           familyi={V\bibinitperiod},
           given={J.\bibnamedelimi Wortman},
           giveni={J\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{0b93dbd18474912bf8001486d6d9c1d7}
      \strng{fullhash}{0b93dbd18474912bf8001486d6d9c1d7}
      \strng{bibnamehash}{0b93dbd18474912bf8001486d6d9c1d7}
      \strng{authorbibnamehash}{0b93dbd18474912bf8001486d6d9c1d7}
      \strng{authornamehash}{0b93dbd18474912bf8001486d6d9c1d7}
      \strng{authorfullhash}{0b93dbd18474912bf8001486d6d9c1d7}
      \strng{editorbibnamehash}{6013a44c5dec47e5e51fdd72b3f8b5eb}
      \strng{editornamehash}{6013a44c5dec47e5e51fdd72b3f8b5eb}
      \strng{editorfullhash}{ad1ea98aa644fe4cbc55fbe24d1f78a9}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Advances in Neural Information Processing Systems}
      \field{title}{Contrastive Active Inference}
      \field{volume}{34}
      \field{year}{2021}
      \field{pages}{13870\bibrangedash 13882}
      \range{pages}{13}
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2021/file/73c730319cf839f143bf40954448ce39-Paper.pdf
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2021/file/73c730319cf839f143bf40954448ce39-Paper.pdf
      \endverb
    \endentry
    \entry{Applications-of-FEP-Machine-Learning-Neuroscience}{thesis}{}
      \name{author}{1}{}{%
        {{hash=dcf103531a4bb5a439a2233cf52e9703}{%
           family={Millidge},
           familyi={M\bibinitperiod},
           given={Beren},
           giveni={B\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {University of Edinburgh}%
      }
      \strng{namehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{fullhash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{bibnamehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{authorbibnamehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{authornamehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{authorfullhash}{dcf103531a4bb5a439a2233cf52e9703}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Applications of the free energy principle to machine learning and neuroscience}
      \field{type}{phdthesis}
      \field{year}{2021}
      \verb{urlraw}
      \verb https://era.ed.ac.uk/handle/1842/38235
      \endverb
      \verb{url}
      \verb https://era.ed.ac.uk/handle/1842/38235
      \endverb
    \endentry
    \entry{Deep-AIF-As-Var-Policy-Grad}{article}{}
      \name{author}{1}{}{%
        {{hash=dcf103531a4bb5a439a2233cf52e9703}{%
           family={Millidge},
           familyi={M\bibinitperiod},
           given={Beren},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{fullhash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{bibnamehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{authorbibnamehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{authornamehash}{dcf103531a4bb5a439a2233cf52e9703}
      \strng{authorfullhash}{dcf103531a4bb5a439a2233cf52e9703}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{07}
      \field{title}{Deep Active Inference as Variational Policy Gradients}
      \field{year}{2019}
      \verb{urlraw}
      \verb https://arxiv.org/pdf/1907.03876.pdf
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/1907.03876.pdf
      \endverb
    \endentry
    \entry{Async-Methods-Deep-RL}{misc}{}
      \name{author}{8}{}{%
        {{hash=f7d23cfe4ca0e6bf7a8c251bfa78aca6}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Volodymyr},
           giveni={V\bibinitperiod}}}%
        {{hash=db6afdf70ea61bf8ed973a75b90ff818}{%
           family={Badia},
           familyi={B\bibinitperiod},
           given={Adrià\bibnamedelima Puigdomènech},
           giveni={A\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=9e80f4779b032f68a6106e1424345450}{%
           family={Mirza},
           familyi={M\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod}}}%
        {{hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=2a321a868e44d49baf52b5e2d816fb71}{%
           family={Lillicrap},
           familyi={L\bibinitperiod},
           given={Timothy\bibnamedelima P.},
           giveni={T\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=b63b9b2d91f6ba1b1739563edc0432ab}{%
           family={Harley},
           familyi={H\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{fullhash}{e067addbfefbaf06a859610fa608b21e}
      \strng{bibnamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorbibnamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authornamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorfullhash}{e067addbfefbaf06a859610fa608b21e}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.LG}
      \field{eprinttype}{arXiv}
      \field{title}{Asynchronous Methods for Deep Reinforcement Learning}
      \field{year}{2016}
      \verb{eprint}
      \verb 1602.01783
      \endverb
    \endentry
    \entry{ATARI-Deep-RL}{misc}{}
      \name{author}{7}{}{%
        {{hash=f7d23cfe4ca0e6bf7a8c251bfa78aca6}{%
           family={Mnih},
           familyi={M\bibinitperiod},
           given={Volodymyr},
           giveni={V\bibinitperiod}}}%
        {{hash=481308b301166b521c74fde6566e97e6}{%
           family={Kavukcuoglu},
           familyi={K\bibinitperiod},
           given={Koray},
           giveni={K\bibinitperiod}}}%
        {{hash=89dbd30410c2085cd059f32c57d4593e}{%
           family={Silver},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=af540e84ef1ecdaa70b1f7c90f59fd7d}{%
           family={Antonoglou},
           familyi={A\bibinitperiod},
           given={Ioannis},
           giveni={I\bibinitperiod}}}%
        {{hash=d7805381550fb5f8360345f7f72c0b49}{%
           family={Wierstra},
           familyi={W\bibinitperiod},
           given={Daan},
           giveni={D\bibinitperiod}}}%
        {{hash=9449802bcb467309c0ebced658096818}{%
           family={Riedmiller},
           familyi={R\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{fullhash}{2860d669102abb5e113bf4232d6d5997}
      \strng{bibnamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorbibnamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authornamehash}{aff24b211b34cdd515b2fd148ce0c920}
      \strng{authorfullhash}{2860d669102abb5e113bf4232d6d5997}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.LG}
      \field{eprinttype}{arXiv}
      \field{title}{Playing Atari with Deep Reinforcement Learning}
      \field{year}{2013}
      \verb{eprint}
      \verb 1312.5602
      \endverb
    \endentry
    \entry{Uncertainty_Epistemics_AIF_Saccad}{article}{}
      \name{author}{2}{}{%
        {{hash=11ecca46a14363f21a56a51e1cb6c0ad}{%
           family={Parr},
           familyi={P\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=558c08870d21f7acad878d94e125a377}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl\bibnamedelima J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{94d447c85e90b56495ba75ac7c353cc3}
      \strng{fullhash}{94d447c85e90b56495ba75ac7c353cc3}
      \strng{bibnamehash}{94d447c85e90b56495ba75ac7c353cc3}
      \strng{authorbibnamehash}{94d447c85e90b56495ba75ac7c353cc3}
      \strng{authornamehash}{94d447c85e90b56495ba75ac7c353cc3}
      \strng{authorfullhash}{94d447c85e90b56495ba75ac7c353cc3}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Biological systems—like ourselves—are constantly faced with uncertainty. Despite noisy sensory data, and volatile environments, creatures appear to actively maintain their integrity. To account for this remarkable ability to make optimal decisions in the face of a capricious world, we propose a generative model that represents the beliefs an agent might possess about their own uncertainty. By simulating a noisy and volatile environment, we demonstrate how uncertainty influences optimal epistemic (visual) foraging. In our simulations, saccades were deployed less frequently to regions with a lower sensory precision, while a greater volatility led to a shorter inhibition of return. These simulations illustrate a principled explanation for some cardinal aspects of visual foraging—and allow us to propose a correspondence between the representation of uncertainty and ascending neuromodulatory systems, complementing that suggested by Yu \&amp; Dayan (Yu \&amp; Dayan 2005 Neuron 46, 681–692. (doi:10.1016/j.neuron.2005.04.026)).}
      \field{journaltitle}{Journal of The Royal Society Interface}
      \field{number}{136}
      \field{title}{Uncertainty, epistemics and active inference}
      \field{volume}{14}
      \field{year}{2017}
      \field{pages}{20170376}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1098/rsif.2017.0376
      \endverb
      \verb{eprint}
      \verb https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2017.0376
      \endverb
      \verb{urlraw}
      \verb https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2017.0376
      \endverb
      \verb{url}
      \verb https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2017.0376
      \endverb
    \endentry
    \entry{Curiosity-Driven-RL}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=09e431093c8637ade01037714cfc992c}{%
           family={Pathak},
           familyi={P\bibinitperiod},
           given={Deepak},
           giveni={D\bibinitperiod}}}%
        {{hash=8386009211558835d056bfe419103c76}{%
           family={Agrawal},
           familyi={A\bibinitperiod},
           given={Pulkit},
           giveni={P\bibinitperiod}}}%
        {{hash=5a663b27298722834a8cf09bb93d8c94}{%
           family={Efros},
           familyi={E\bibinitperiod},
           given={Alexei\bibnamedelima A.},
           giveni={A\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=90180e1a30742e0d15328bfe637c2ef4}{%
           family={Darrell},
           familyi={D\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=4428b76e1301b2db58587fb18bb59a38}{%
           family={Precup},
           familyi={P\bibinitperiod},
           given={Doina},
           giveni={D\bibinitperiod}}}%
        {{hash=a71fae003da84f44e31d26e868859945}{%
           family={Teh},
           familyi={T\bibinitperiod},
           given={Yee\bibnamedelima Whye},
           giveni={Y\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {PMLR}%
      }
      \strng{namehash}{a353c16f2bb5e07676f9be9b2c866db4}
      \strng{fullhash}{5e51aa99fa833fb4f48cba575f1027fd}
      \strng{bibnamehash}{a353c16f2bb5e07676f9be9b2c866db4}
      \strng{authorbibnamehash}{a353c16f2bb5e07676f9be9b2c866db4}
      \strng{authornamehash}{a353c16f2bb5e07676f9be9b2c866db4}
      \strng{authorfullhash}{5e51aa99fa833fb4f48cba575f1027fd}
      \strng{editorbibnamehash}{ee1b5a05452f2afba9cd287be3ce0338}
      \strng{editornamehash}{ee1b5a05452f2afba9cd287be3ce0338}
      \strng{editorfullhash}{ee1b5a05452f2afba9cd287be3ce0338}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.}
      \field{booktitle}{Proceedings of the 34th International Conference on Machine Learning}
      \field{month}{06--11 Aug}
      \field{series}{Proceedings of Machine Learning Research}
      \field{title}{Curiosity-driven Exploration by Self-supervised Prediction}
      \field{volume}{70}
      \field{year}{2017}
      \field{pages}{2778\bibrangedash 2787}
      \range{pages}{10}
      \verb{file}
      \verb http://proceedings.mlr.press/v70/pathak17a/pathak17a.pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v70/pathak17a.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v70/pathak17a.html
      \endverb
    \endentry
    \entry{Step-by-Step-Tutorial-AIF-Empirical-Data}{article}{}
      \name{author}{3}{}{%
        {{hash=2375765385b5498bd2826de02ade4c7d}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod}}}%
        {{hash=558c08870d21f7acad878d94e125a377}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl\bibnamedelima J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=b241685664e7de7eae8f0f2c6a1a869d}{%
           family={Whyte},
           familyi={W\bibinitperiod},
           given={Christopher\bibnamedelima J.},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{a32bfe6aab2332411e701acebc914238}
      \strng{fullhash}{a32bfe6aab2332411e701acebc914238}
      \strng{bibnamehash}{a32bfe6aab2332411e701acebc914238}
      \strng{authorbibnamehash}{a32bfe6aab2332411e701acebc914238}
      \strng{authornamehash}{a32bfe6aab2332411e701acebc914238}
      \strng{authorfullhash}{a32bfe6aab2332411e701acebc914238}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The active inference framework, and in particular its recent formulation as a partially observable Markov decision process (POMDP), has gained increasing popularity in recent years as a useful approach for modeling neurocognitive processes. This framework is highly general and flexible in its ability to be customized to model any cognitive process, as well as simulate predicted neuronal responses based on its accompanying neural process theory. It also affords both simulation experiments for proof of principle and behavioral modeling for empirical studies. However, there are limited resources that explain how to build and run these models in practice, which limits their widespread use. Most introductions assume a technical background in programming, mathematics, and machine learning. In this paper we offer a step-by-step tutorial on how to build POMDPs, run simulations using standard MATLAB routines, and fit these models to empirical data. We assume a minimal background in programming and mathematics, thoroughly explain all equations, and provide exemplar scripts that can be customized for both theoretical and empirical studies. Our goal is to provide the reader with the requisite background knowledge and practical tools to apply active inference to their own research. We also provide optional technical sections and multiple appendices, which offer the interested reader additional technical details. This tutorial should provide the reader with all the tools necessary to use these models and to follow emerging advances in active inference research.}
      \field{issn}{0022-2496}
      \field{journaltitle}{Journal of Mathematical Psychology}
      \field{title}{A step-by-step tutorial on active inference and its application to empirical data}
      \field{volume}{107}
      \field{year}{2022}
      \field{pages}{102632}
      \range{pages}{1}
      \verb{doi}
      \verb https://doi.org/10.1016/j.jmp.2021.102632
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0022249621000973
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0022249621000973
      \endverb
      \keyw{Active inference,Computational neuroscience,Bayesian inference,Learning,Decision-making,Machine learning}
    \endentry
    \entry{Reinforcement-Learning-An-Introduction}{book}{}
      \name{author}{2}{}{%
        {{hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S.},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=32a0a208f8bcf56a13b0a8e618aa806a}{%
           family={Barto},
           familyi={B\bibinitperiod},
           given={Andrew\bibnamedelima G.},
           giveni={A\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cambridge, Massachusetts}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{c6212f1a1407d96a3d9f4fefbb07eade}
      \strng{fullhash}{c6212f1a1407d96a3d9f4fefbb07eade}
      \strng{bibnamehash}{c6212f1a1407d96a3d9f4fefbb07eade}
      \strng{authorbibnamehash}{c6212f1a1407d96a3d9f4fefbb07eade}
      \strng{authornamehash}{c6212f1a1407d96a3d9f4fefbb07eade}
      \strng{authorfullhash}{c6212f1a1407d96a3d9f4fefbb07eade}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{edition}{2}
      \field{title}{Reinforcement Learning: An Introduction}
      \field{year}{2018}
    \endentry
    \entry{Reinforcement-Learning-Through-AIF}{misc}{}
      \name{author}{4}{}{%
        {{hash=3f98dc382188ff01295eb411612cb9ae}{%
           family={Tschantz},
           familyi={T\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=dcf103531a4bb5a439a2233cf52e9703}{%
           family={Millidge},
           familyi={M\bibinitperiod},
           given={Beren},
           giveni={B\bibinitperiod}}}%
        {{hash=a18faa5d293b699968705a564971492b}{%
           family={Seth},
           familyi={S\bibinitperiod},
           given={Anil\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=6ba2af6672c84ba8cffc8b86bc35d608}{%
           family={Buckley},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima L.},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{fullhash}{20ddd33b6e9bbc0e302a3feb1773a6c9}
      \strng{bibnamehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{authorbibnamehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{authornamehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{authorfullhash}{20ddd33b6e9bbc0e302a3feb1773a6c9}
      \field{extraname}{1}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprintclass}{cs.LG}
      \field{eprinttype}{arXiv}
      \field{title}{Reinforcement Learning through Active Inference}
      \field{year}{2020}
      \verb{eprint}
      \verb 2002.12636
      \endverb
    \endentry
    \entry{Scaling-AIF}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=3f98dc382188ff01295eb411612cb9ae}{%
           family={Tschantz},
           familyi={T\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=fa7c84e2ae98e6ac22617182c34e9972}{%
           family={Baltieri},
           familyi={B\bibinitperiod},
           given={Manuel},
           giveni={M\bibinitperiod}}}%
        {{hash=a18faa5d293b699968705a564971492b}{%
           family={Seth},
           familyi={S\bibinitperiod},
           given={Anil.\bibnamedelimi K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=6ba2af6672c84ba8cffc8b86bc35d608}{%
           family={Buckley},
           familyi={B\bibinitperiod},
           given={Christopher\bibnamedelima L.},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{fullhash}{ac27dbea74c8ba6d7e3bc2a74e7705ec}
      \strng{bibnamehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{authorbibnamehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{authornamehash}{c1308c02024dfc243c971e68d399eb80}
      \strng{authorfullhash}{ac27dbea74c8ba6d7e3bc2a74e7705ec}
      \field{extraname}{2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2020 International Joint Conference on Neural Networks (IJCNN)}
      \field{title}{Scaling Active Inference}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/IJCNN48605.2020.9207382
      \endverb
    \endentry
    \entry{Deep-AIF}{article}{}
      \name{author}{1}{}{%
        {{hash=9de7ac13a278cef9d0816984a9ab8273}{%
           family={Ueltzhöffer},
           familyi={U\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{2}{%
        {Springer Science}%
        {Business Media {LLC}}%
      }
      \strng{namehash}{9de7ac13a278cef9d0816984a9ab8273}
      \strng{fullhash}{9de7ac13a278cef9d0816984a9ab8273}
      \strng{bibnamehash}{9de7ac13a278cef9d0816984a9ab8273}
      \strng{authorbibnamehash}{9de7ac13a278cef9d0816984a9ab8273}
      \strng{authornamehash}{9de7ac13a278cef9d0816984a9ab8273}
      \strng{authorfullhash}{9de7ac13a278cef9d0816984a9ab8273}
      \field{sortinit}{U}
      \field{sortinithash}{6901a00e45705986ee5e7ca9fd39adca}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{howpublished}{\url{https://doi.org/10.1007\%2Fs00422-018-0785-7}}
      \field{journaltitle}{Biological Cybernetics}
      \field{month}{10}
      \field{number}{6}
      \field{title}{Deep active inference}
      \field{volume}{112}
      \field{year}{2018}
      \field{pages}{547\bibrangedash 573}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1007/s00422-018-0785-7
      \endverb
    \endentry
    \entry{Factor-Graph-Desc-Deep-Temp-AIF}{article}{}
      \name{author}{2}{}{%
        {{hash=2caeea1b18c3a6d6099b66a5232eb983}{%
           family={Vries},
           familyi={V\bibinitperiod},
           given={Bert},
           giveni={B\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
        {{hash=558c08870d21f7acad878d94e125a377}{%
           family={Friston},
           familyi={F\bibinitperiod},
           given={Karl\bibnamedelima J.},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{9bf9c52581ee658cb652bbab2b792dd9}
      \strng{fullhash}{9bf9c52581ee658cb652bbab2b792dd9}
      \strng{bibnamehash}{9bf9c52581ee658cb652bbab2b792dd9}
      \strng{authorbibnamehash}{9bf9c52581ee658cb652bbab2b792dd9}
      \strng{authornamehash}{9bf9c52581ee658cb652bbab2b792dd9}
      \strng{authorfullhash}{9bf9c52581ee658cb652bbab2b792dd9}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Active inference is a corollary of the Free Energy Principle that prescribes how self-organizing biological agents interact with their environment. The study of active inference processes relies on the definition of a generative probabilistic model and a description of how a free energy functional is minimized by neuronal message passing under that model. This paper presents a tutorial introduction to specifying active inference processes by Forney-style factor graphs (FFG). The FFG framework provides both an insightful representation of the probabilistic model and a biologically plausible inference scheme that, in principle, can be automatically executed in a computer simulation. As an illustrative example, we present an FFG for a deep temporal active inference process. The graph clearly shows how policy selection by expected free energy minimization results from free energy minimization per se, in an appropriate generative policy model.}
      \field{issn}{1662-5188}
      \field{journaltitle}{Frontiers in Computational Neuroscience}
      \field{title}{A Factor Graph Description of Deep Temporal Active Inference}
      \field{volume}{11}
      \field{year}{2017}
      \verb{doi}
      \verb 10.3389/fncom.2017.00095
      \endverb
      \verb{urlraw}
      \verb https://www.frontiersin.org/articles/10.3389/fncom.2017.00095
      \endverb
      \verb{url}
      \verb https://www.frontiersin.org/articles/10.3389/fncom.2017.00095
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

