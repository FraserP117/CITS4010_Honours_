### The FEP
The basic insight is that if a system maintains a boundary between itself and some exterior environment, and if this system persists over time, then this system must be capable of resisting the thermodynamic tendency toward the dissolution of the boundary which separates its internal states from the external environment. To do this, the system must maintain the configuration of its internal states so as to exist within some desired homeostatic bounds. The way the system can achieve this is by maximizing the Bayesian model-evidence for its configuration of internal states. Hence we have internal states, external states and ``blanket'' states, where the blanket states are themselves composed of ``active'' and ``sensory'' states. Internal states can only be directly influenced by the sensory states of the blanket, and external states can only be influenced by the active states of the blanket. The Bayesian model evidence for the system's configuration of internal states is bounded above by the free energy of the system's Bayesian beliefs about the sensory states. Hence the ``Free Energy'' principle, since the Free Energy serves as a tractable upper bound to the system's model evidence. Thus the principle culminates in the following statement. Any system which persists across time, in the face of a tendency to thermodynamic dissolution must act as if it is soliciting evidence for its own existence, via a model of the world.  

See Figure \ref{fig:FEP} for a diagrammatic exposition of the relationship between these variables.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{FEP}
  \caption{A depiction of the various sets of states and their relationships in the FEP}
  \label{fig:FEP}
\end{figure}


\section{Overall Plan/Scaffold}

This is simply the list of papers I intend on citing. I won't be able to cite all of them but I think it's best to write what I think I need to write and then cull.

Introductory/Context-Affording papers:
\begin{enumerate}
	\item ``The free-energy principle: a rough guide to the brain?'': \textcite{FEP-Rough-Guide-Brain}
	\item ``Reinforcement Learning: An Introduction'': \textcite{Reinforcement-Learning-An-Introduction}
	\item ``Action and behavior: a free-energy formulation'': \textcite{Action-Behaviour-FE}
	\item ``Mastering the game of Go without human knowledge'': \textcite{Mastering-Go-Without-Human-Knowledge}

	\item Issue scaling AIF ``Active inference on discrete state-spaces: A synthesis'': \textcite{AIF-Discrete-Action-Spaces-Synthesis}
	\item Issue scaling AIF ``A step-by-step tutorial on active inference and its application to empirical data'': \textcite{Step-by-Step-Tutorial-AIF-Empirical-Data}
	\item Issue scaling AIF ``Applications of the FEP to ML and Neuroscience'': \textcite{Applications-of-FEP-Machine-Learning-Neuroscience}

	\item Contemporary RL Method ``Asynchronous Methods for Deep Reinforcement Learning'': \textcite{Async-Methods-Deep-RL}
	\item Contemporary RL Method ``Playing Atari with Deep Reinforcement Learning'': \textcite{ATARI-Deep-RL}

	\item ``Reinforcement Learning or Active Inference?'': \textcite{RL-or-AIF}
	\item ``The FEP for action and perception a mathematical review'': \textcite{FEP-Mathematical-Review}
	\item ``The Bayesian brain: the role of uncertainty in neural coding and computation'': \textcite{The-Bayesian-Brain}
	\item ``An empirical evaluation of active inference in multi-armed bandits'': \textcite{Emperical-Eval-AIF-Multi-Arm-Bandits}
	% \item "": \textcite{}
\end{enumerate}

Neural Network Approximators:
\begin{enumerate}
	\item ``Applications of the FEP to ML and Neuroscience'': \textcite{Applications-of-FEP-Machine-Learning-Neuroscience}
	\item ``Deep Active Inference'': \textcite{Deep-AIF}
	\item ``Deep Active Inference as Variational Policy Gradients'': \textcite{Deep-AIF-As-Var-Policy-Grad}
	\item ``Scaling Active Inference'': \textcite{Scaling-AIF}
	\item ``Reinforcement Learning Through Active Inference'': \textcite{Reinforcement-Learning-Through-AIF}
	\item ``Bayesian Policy Selection Using Active Inference'': \textcite{Bayesian-Policy-Selection-Using-AIF}
	\item ``Contrastive Active Inference'': \textcite{Contrastive-AIF}
\end{enumerate}

Factor Graph and Message Passing Implementations
\begin{enumerate}
	\item ``Codes on graphs: normal realizations'': \textcite{Codes-on-Graphs}
	\item ``Simulating Active Inference by Message Passing'': \textcite{Simulating-AIF-By-Message-Passing}
	\item ``Applications of the FEP to ML and Neuroscience'': \textcite{Applications-of-FEP-Machine-Learning-Neuroscience}
	\item ``A factor graph approach to automated design of Bayesian signal processing algorithms'': \textcite{Factor-Graph-Approach-Automated-Design-Bayesian-Algos}
	\item ``Reactive Message Passing for Scalable Bayesian Inference": \textcite{Reactive-MP}
	\item ``A Factor Graph Description of Deep Temporal Active Inference'': \textcite{Factor-Graph-Desc-Deep-Temp-AIF}
	\item ``Deep Active Inference for Partially Observable MDPs'': \textcite{DEEP-AIF-For-POMDPs}
	\item ``Bayesian policy selection using active inference'': \textcite{Bayesian-Policy-Selection-AIF}
\end{enumerate}

Finally, address the specific papers on Scaling that I'll use:
\begin{enumerate}
	\item Sampling/Neural Networks ``Scaling Active Inference'': \textcite{Scaling-AIF}
	\item Sampling?/neural nets? "``Contrastive Active Inference'': \textcite{Contrastive-AIF}
\end{enumerate}

Other Papers:
\begin{enumerate}
	\item Paper: ``The FEP for action and perception a mathematical review'': \textcite{FEP-Mathematical-Review}
	\item paper: ``Simulating Active Inference by Message Passing'': \textcite{Simulating-AIF-By-Message-Passing}
	\item Paper: ``a practical tutorial on Variational Bayes'': \textcite{Practical-Tutorial-Variational-Bayes}
	\item Paper: ``action and behavior, a free energy formulation'': \textcite{Action-Behaviour-FE}
	\item paper: ``A tutorial on the free-energy framework for modelling perception and learning'': \textcite{Tutorial-FEP-Modelling-Perception-Action}
	\item Paper: â€œA step-by-step tutorial on active inference and its application to empirical data'': \textcite{Step-by-Step-Tutorial-AIF-Empirical-Data}
	\item Paper: ``Scaling Active Inference'': \textcite{Scaling-AIF}
	\item paper: The Cape Town AIF/RL Honours Thesis - not sure if published/if appropriate
	\item PhD Thesis: ``Applications of the FEP to ML and Neuroscience'': \textcite{Applications-of-FEP-Machine-Learning-Neuroscience}
\end{enumerate}




% @article{Scaling-AIF,
%   author    = {Alexander Tschantz and
%                Manuel Baltieri and
%                Anil K. Seth and
%                Christopher L. Buckley},
%   title     = {Scaling active inference},
%   journal   = {CoRR},
%   volume    = {abs/1911.10601},
%   year      = {2019},
%   url       = {http://arxiv.org/abs/1911.10601},
%   eprinttype = {arXiv},
%   eprint    = {1911.10601},
%   timestamp = {Tue, 03 Dec 2019 14:15:54 +0100},
%   biburl    = {https://dblp.org/rec/journals/corr/abs-1911-10601.bib},
%   bibsource = {dblp computer science bibliography, https://dblp.org}
% }

## robustness to non-stationarity
\textcite{Emperical-Eval-AIF-Multi-Arm-Bandits} implemented an Active Inference agent for the multi-armed bandit problem, in the stationary and non-stationary case. In the stationary case, this agent Active did not perform as well as a special purpose, state-of-the-art Bayesian UCB algorithm. However in the non-stationary case, the Active Inference agent outperformed the UCB agent. While this implementation was conducted over a small, discrete state-action space, the results plausibly suggest that Active Inference would be an effective means of robust inference and control in a higher-dimensional or continuous problem.  

\subsection{Variational Inference}
Variational inference: \textcite{Variational-Inference-Reviews} is a technique of approximate Bayesian inference, in the case that the exact inference procedure becomes intractible, typically due to the large or infinite number of states over which it is necessary to marginalise. The goal in all Bayesian inference methods is to compute the posterior distribution over some variable, given the prior and liklihood distributions. These latter encode - respectively - the supposed causal relationship between the variable of interest and a observation, in addition to a ``prior'' belief about the distribution of the variable at issue. If we wish to infer the posterior distribution of $x$ as a consequence of observing $y$, then this is given as the distribution: $p(x | y)$ and bayes's rule gives: 

$$ p(x | y) = \frac{p(y | x)p(x)}{p(y)}$$

For all but the smallest problems, computing the posterior exactly is intractible, due to the sheer number of states over which it is necessary to sum/integrate when computing $p(y)$. To eschew this, variational inference proposes an approximation scheme, whereby a family of ``variational'' or ``approximate'' posterior distributions is posited, each of which is a potential, appoximate solution to the true posterior. These approximate posteriors are usiually denoted: $q_i(x)$ where the subscript denotes that this is the ith member of the family. We select a particular approximate posterior by chosing the one with the smalest ``divergence'' from the true posterior. Typically this is the Kullback-Libeler Divergence (KL Divergence). 

\subsection{The Free Energy Principle}

Historically speaking, Active Inference is a derivative of the ``Free Energy Principle'', which is a theoretical principle thought to plausibly offer a unified, constitutive account of brain function: \textcite{FEP-Rough-Guide-Brain} and perhaps even of life itself: \textcite{Life-As-We-Know-It}. 

The Free Energy Principle (FEP) attempts to provide a principled account of adaptivity per-se. The basic insight is that if a system maintains a boundary between itself and some exterior environment, and if this system persists over time, then this system must be capable of resisting the thermodynamic tendency toward the dissolution of the boundary which separates its internal states from the external environment. To do this, the system must maintain the configuration of its internal states so as to exist within some desired homeostatic bounds. The way the system can achieve this is by maximizing the Bayesian model-evidence for its configuration of internal states. Hence we have internal states, external states and ``blanket'' states, where the blanket states are themselves composed of ``active'' and ``sensory'' states. Internal states can only be directly influenced by the sensory states of the blanket, and external states can only be influenced by the active states of the blanket. The Bayesian model evidence for the system's configuration of internal states is bounded above by the free energy of the system's Bayesian beliefs about the sensory states. Hence the ``Free Energy'' principle, since the Free Energy serves as a tractable upper bound to the system's model evidence. Thus the principle culminates in the following statement. Any system which persists across time, in the face of a tendency to thermodynamic dissolution must act as if it is soliciting evidence for its own existence, via a model of the world.  

\subsection{Present Questions}

Although Active Inference offers several exciting new directions in agent-based AI and might hold the key to truly sample-efficient real-world implementations, the theory has typically only been implemented on relatively trivial problem instances, with a small number of states and/or actions, most commonly in a discrete setting: \textcite{Uncertainty_Epistemics_AIF_Saccad} and \textcite{AIF-Epistemic-Value}. Although it has been used to great effect in these ``proof of concept'' cases, it is not yet applicable to the same sorts of problems that reinforcement learning can curently address. Many of the sorts of real-world applications of practical interest are thus far beyond the reach of Active Inference, especially for real-time implementations. The main difficulty stems from the fact that the variational free energy is a functional of hidden states and observations. Hidden states are usually exist in a very high dimensional space and observations are usually highly time-varying. The task of minimising a highly dimensional, time-varying functional is non-trivial. The goal of scaling up the method to problems with larger state and/or action spaces, such as in the continuous case, is very much an open one, and one that must be satisfacotrially adressed if Active Inference is to become a serious contender as a real-world method.  

\subsection{Active Inference: Key Concepts} 



% \subsection{Overview of Research Direction}

% The central aim of my proposed research topic is twofold. The first constituent aim is to investigate the relative merits/demerits of active inference as a real-world control and optimization strategy, against reinforcement learning baselines. I propose to investigate this by framing the question of real-world suitability in terms of the approach's ability to afford fast and reliable solutions in noisy, uncertain or partially observable environments. the subsequent active inference agents I develop will be compared to Reinforcement Learning baselines. 

% The second aim concerns the potential for ``scaling up'' Active Inference methods to continuous and/or higher-dimensional state-spaces. This is a natural corollary to the first aim, since if we are interested in the suitability of Active Inference as a real-world control and optimization technique, it is not enough to simply determine if it can favorably compare to an established method in the noisy case. Since the real-world tasks of interest are overwhelmingly characterized by a high degree of dimensionality, it is necessary to investigate the performance of Active inference in high-dimensional settings.  

% Thus are the central questions raised in this Thesis:

% \begin{itemize}
% \item Are Active Inference agents more robust to noisy observations and non-stationarity than a comparable RL baseline?
% \item What are the most promising avenues of investigation in the attempt to scale up active inference to larger problem instances? 
% \end{itemize} 

\subsubsection{The Free Energy Principle}

Historically speaking, Active Inference is a derivative of the ``Free Energy Principle'', which is a theoretical principle thought to plausibly offer a unified, constitutive account of brain function: \textcite{FEP-Rough-Guide-Brain} and perhaps even of life itself: \textcite{Life-As-We-Know-It}. 

The Free Energy Principle (FEP) attempts to provide a principled account of adaptivity per-se. The basic insight is that if a system maintains a boundary between itself and some exterior environment, and if this system persists over time, then this system must be capable of resisting the thermodynamic tendency toward the dissolution of the boundary which separates its internal states from the external environment. To do this, the system must maintain the configuration of its internal states so as to exist within some desired homeostatic bounds. The way the system can achieve this is by maximizing the Bayesian model-evidence for its configuration of internal states. Hence we have internal states, external states and ``blanket'' states, where the blanket states are themselves composed of ``active'' and ``sensory'' states. Internal states can only be directly influenced by the sensory states of the blanket, and external states can only be influenced by the active states of the blanket. The Bayesian model evidence for the system's configuration of internal states is bounded above by the free energy of the system's Bayesian beliefs about the sensory states. Hence the ``Free Energy'' principle, since the Free Energy serves as a tractable upper bound to the system's model evidence. Thus the principle culminates in the following statement. Any system which persists across time, in the face of a tendency to thermodynamic dissolution must act as if it is soliciting evidence for its own existence, via a model of the world. 
